{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the files\n",
    "\n",
    "The first challenge within this data science challenge is to get the data: it is massive. According to the [challenge's website](), the data can either be downloaded from a web server, or downloaded through torrents. Since I wanted to automate that, I have decided to include it in the tutorial.\n",
    "\n",
    "The reason I decided to automate this task are simple:\n",
    "1. I am using a compute instance on Microsoft Azure to write and test these notebooks. The instances I am using has the required necessary disk space, but on a temporary disk. Data on these disk are not guaranteed to be persistent when this type of Virtual Machine restarts. Since I intend on scheduling the start/stop time of the Virtual Machine, I will lose data every time I reboot. I have considered using Azure Machine Learning's Datasets and Datastores, and although they are easy to configure, I have decided instead to write the script below, to include it in the tutorial.\n",
    "2. Automation could also be very useful if we decided to build a data pipeline in the future\n",
    "3. I wanted to explore `multiprocessing` a little bit more. I know the data will be huge and I am already imagining that I will need to write code that can scale on multiple CPU cores easily.\n",
    "\n",
    "## The script\n",
    "\n",
    "The download script, named `download_data.py` is in the folder \"LUNA16/utils/download_data.py\". It takes 1 argument: the destination folder.\n",
    "The script would then launch a set of workers in a multiprocessing pool (2x number of cores), where each worker performs two things:\n",
    "1. Downloads a file\n",
    "2. If it's a ZIP file, unzip it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction and download instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our journey so far\n",
    "This concludes the first notebook of the series! to wrap up, Here is our status by now:\n",
    "\n",
    "- [x] Learnt how to use `requests` to download some files, and `unzip` them.\n",
    "- [x] Learnt how to perform this operation in parallel, to make the download as fast as possible.\n",
    "- [ ] How many files have we downloaded? How many folders? What are their extensions? All of this is covered in [01-Understanding files and folders](01%20-%20Understanding%20files%20and%20folders%20EDA.ipynb)\n",
    "\n",
    "See you in the next notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9169f1d4e16acc976bbb73e323b0dbdf23f1c55e833fb2befffc4fb50ac2de2f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 ('azureml_py38_PT_TF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
